<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">

<meta name="theme-color" content="#f8f5ec">
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="description" content="TensorFlow Android walkthrough"><meta name="keywords" content="android"><link rel="alternate" href="/default" title="Lynn8570's Blog"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=2.11.0">
<link rel="canonical" href="https://lynn8570.github.io/2018/05/31/tensorflow/">

<link rel="stylesheet" type="text/css" href="/lib/fancybox/jquery.fancybox.css"><link rel="stylesheet" type="text/css" href="/lib/nprogress/nprogress.min.css">
<link rel="stylesheet" type="text/css" href="/css/style.css?v=2.11.0">

<script id="baidu_push">
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>
<script>
  window.config = {"leancloud":{"app_id":null,"app_key":null},"toc":true,"fancybox":true,"pjax":true,"latex":false};
</script>

    <title>TensorFlow Android walkthrough - Lynn8570's Blog</title>
  </head>

  <body><div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/." class="logo">Lynn8570's Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>

<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list"><a href="/">
        <li class="mobile-menu-item">首页
          </li>
      </a></ul>
</nav>
<div class="container" id="mobile-panel">
      <header id="header" class="header"><div class="logo-wrapper">
  <a href="/." class="logo">Lynn8570's Blog</a>
</div>

<nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item">
          <a class="menu-item-link" href="/">
            首页
            </a>
        </li>
      </ul></nav>
</header>

      <main id="main" class="main">
        <div class="content-wrapper">
          <div id="content" class="content"><article class="post">
    <header class="post-header">
      <h1 class="post-title">TensorFlow Android walkthrough
        </h1>

      <div class="post-meta">
        <span class="post-time">
          2018-05-31
        </span><span class="post-category">
            <a href="/categories/TensorFlow/">TensorFlow</a>
            </span>
        </div>
    </header>

    <div class="post-toc" id="post-toc">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#用pip-安装tensor-flow"><span class="toc-text">用pip 安装tensor flow</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#android-的环境"><span class="toc-text">android 的环境</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#下载GitHub-源码"><span class="toc-text">下载GitHub 源码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Android-demo-walkthrough"><span class="toc-text">Android demo walkthrough</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#归类识别classifier"><span class="toc-text">归类识别classifier</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#检测-detector"><span class="toc-text">检测 detector</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#训练模型"><span class="toc-text">训练模型</span></a></li></ol>
    </div>
  </div><div class="post-content"><p>【链接】tensorflow/tensorflow<br><a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android</a></p>
<h1 id="用pip-安装tensor-flow"><a href="#用pip-安装tensor-flow" class="headerlink" title="用pip 安装tensor flow"></a>用pip 安装tensor flow</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.0.0-py3-none-any.whl</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.6.0-py3-none-any.whl</span><br><span class="line"></span><br><span class="line"> Downloading https://storage.googleapis.com/tensorflow/mac/tensorflow-0.6.0-py3-none-any.whl (10.2MB)</span><br><span class="line">    100% |████████████████████████████████| 10.3MB 1.9MB/s </span><br><span class="line">Collecting numpy&gt;=1.8.2 (from tensorflow==0.6.0)</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/8e/75/7a8b7e3c073562563473f2a61bd53e75d0a1f5e2047e576ee61d44113c22/numpy-1.14.3-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (4.7MB)</span><br><span class="line">    100% |████████████████████████████████| 4.7MB 832kB/s </span><br><span class="line">Collecting protobuf==3.0.0a3 (from tensorflow==0.6.0)</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/d7/92/34c5810fa05e98082d141048110db97d2f98d318fa96f8202bf146ab79de/protobuf-3.0.0a3.tar.gz (88kB)</span><br><span class="line">    100% |████████████████████████████████| 92kB 18.6MB/s </span><br><span class="line">Requirement not upgraded as not directly required: wheel&gt;=0.26 in ./venv/lib/python3.6/site-packages (from tensorflow==0.6.0) (0.31.1)</span><br><span class="line">Collecting six&gt;=1.10.0 (from tensorflow==0.6.0)</span><br><span class="line">  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl</span><br><span class="line">Requirement not upgraded as not directly required: setuptools in ./venv/lib/python3.6/site-packages (from protobuf==3.0.0a3-&gt;tensorflow==0.6.0) (39.1.0)</span><br><span class="line">Building wheels for collected packages: protobuf</span><br><span class="line">  Running setup.py bdist_wheel for protobuf ... done</span><br><span class="line">  Stored in directory: /Users/zowee-laisc/Library/Caches/pip/wheels/07/0a/98/ca8fbec7368a85849700304bf0cf40d2d8e183f9a5dd136795</span><br><span class="line">Successfully built protobuf</span><br><span class="line">Installing collected packages: numpy, protobuf, six, tensorflow</span><br><span class="line">Successfully installed numpy-1.14.3 protobuf-3.0.0a3 six-1.11.0 tensorflow-0.6.0</span><br><span class="line">(venv) zowee-laiscdeMacBook-Pro:tensorflow zowee-laisc$</span><br></pre></td></tr></table></figure>

<p>就这么简单，然后测试环境ok</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">(venv) zowee-laiscdeMacBook-Pro:tensorflow zowee-laisc$ python</span><br><span class="line">Python 3.6.4 (v3.6.4:d48ecebad5, Dec 18 2017, 21:07:28) </span><br><span class="line">[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">&gt;&gt;&gt; import tensorflow as tf</span><br><span class="line">&gt;&gt;&gt; hello = tf.constant(&apos;hello tensorflow&apos;)</span><br><span class="line">&gt;&gt;&gt; sess = tf.Session()</span><br><span class="line">I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 4</span><br><span class="line">I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 4</span><br><span class="line">&gt;&gt;&gt; print(sess.run(hello))</span><br><span class="line">b&apos;hello tensorflow&apos;</span><br><span class="line">&gt;&gt;&gt; a = tf.constant(10)</span><br><span class="line">&gt;&gt;&gt; b = tf.constant(32)</span><br><span class="line">&gt;&gt;&gt; print(sess.run(a+b))</span><br><span class="line">42</span><br><span class="line">&gt;&gt;&gt; exit();</span><br></pre></td></tr></table></figure>

<p>python3运行起来有些问题，后面把环境换成python2.7了，</p>
<p>Pycharm 配置python版本为 2.7，然后激活虚拟环境即可。</p>
<h1 id="android-的环境"><a href="#android-的环境" class="headerlink" title="android 的环境"></a>android 的环境</h1><h2 id="下载GitHub-源码"><a href="#下载GitHub-源码" class="headerlink" title="下载GitHub 源码"></a>下载GitHub 源码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git</span><br></pre></td></tr></table></figure>

<p>将example下的Android目录作为项目根目录，用android studio直接打开就可以了</p>
<p>将buildsystem改为 cmake，编译。</p>
<h2 id="Android-demo-walkthrough"><a href="#Android-demo-walkthrough" class="headerlink" title="Android demo walkthrough"></a>Android demo walkthrough</h2><h3 id="归类识别classifier"><a href="#归类识别classifier" class="headerlink" title="归类识别classifier"></a>归类识别classifier</h3><p>ClassifierActivity 用于识别分类的，继承了基础类CameraActivity</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public class ClassifierActivity extends CameraActivity implements OnImageAvailableListener &#123;</span><br></pre></td></tr></table></figure>

<p>其中CameraActivity封装了一些camera的操作</p>
<p>先查看下CameraActivity的代码</p>
<p>在onCreate的时候</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">protected void onCreate(final Bundle savedInstanceState) &#123;</span><br><span class="line">  LOGGER.d(&quot;onCreate &quot; + this);</span><br><span class="line">  super.onCreate(null);</span><br><span class="line">  //设置屏幕常亮，只要给该window对用户可见的时候，保持屏幕亮屏</span><br><span class="line">  getWindow().addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);</span><br><span class="line"></span><br><span class="line">  setContentView(R.layout.activity_camera);</span><br><span class="line">  if (hasPermission()) &#123;</span><br><span class="line">    setFragment();</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    requestPermission();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中setFragment()</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">protected void setFragment() &#123;</span><br><span class="line">    String cameraId = chooseCamera();//选择合适的camera</span><br><span class="line">    if (cameraId == null) &#123;</span><br><span class="line">      Toast.makeText(this, &quot;No Camera Detected&quot;, Toast.LENGTH_SHORT).show();</span><br><span class="line">      finish();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Fragment fragment;</span><br><span class="line">    if (useCamera2API) &#123;//true 初始化fragment</span><br><span class="line">      CameraConnectionFragment camera2Fragment =</span><br><span class="line">          CameraConnectionFragment.newInstance(</span><br><span class="line">              new CameraConnectionFragment.ConnectionCallback() &#123;</span><br><span class="line">                @Override</span><br><span class="line">                public void onPreviewSizeChosen(final Size size, final int rotation) &#123;</span><br><span class="line">                  Log.i(&quot;linlian&quot;,&quot;useCamera2API onPreviewSizeChosen=&quot;);</span><br><span class="line">                  previewHeight = size.getHeight();</span><br><span class="line">                  previewWidth = size.getWidth();</span><br><span class="line">                  CameraActivity.this.onPreviewSizeChosen(size, rotation);</span><br><span class="line">                &#125;</span><br><span class="line">              &#125;,</span><br><span class="line">              this,</span><br><span class="line">              getLayoutId(),</span><br><span class="line">              getDesiredPreviewFrameSize());</span><br><span class="line"></span><br><span class="line">      camera2Fragment.setCamera(cameraId);</span><br><span class="line">      fragment = camera2Fragment;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      fragment =</span><br><span class="line">          new LegacyCameraConnectionFragment(this, getLayoutId(), getDesiredPreviewFrameSize());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">   //将合适的fragment添加到Activity中</span><br><span class="line">    getFragmentManager()</span><br><span class="line">        .beginTransaction()</span><br><span class="line">        .replace(R.id.container, fragment)</span><br><span class="line">        .commit();</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>其中CameraConnectionFragment，对应布局为<code>protected int getLayoutId() {  return R.layout.camera_connection_fragment;}</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&lt;RelativeLayout xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot;</span><br><span class="line">    android:layout_width=&quot;match_parent&quot;</span><br><span class="line">    android:layout_height=&quot;match_parent&quot;&gt;</span><br><span class="line"></span><br><span class="line">    &lt;org.tensorflow.demo.AutoFitTextureView</span><br><span class="line">        android:id=&quot;@+id/texture&quot;</span><br><span class="line">        android:layout_width=&quot;wrap_content&quot;</span><br><span class="line">        android:layout_height=&quot;wrap_content&quot;</span><br><span class="line">        android:layout_alignParentBottom=&quot;true&quot; /&gt; </span><br><span class="line"></span><br><span class="line">    &lt;org.tensorflow.demo.RecognitionScoreView</span><br><span class="line">        android:id=&quot;@+id/results&quot;</span><br><span class="line">        android:layout_width=&quot;match_parent&quot;</span><br><span class="line">        android:layout_height=&quot;112dp&quot;</span><br><span class="line">        android:layout_alignParentTop=&quot;true&quot; /&gt; 用于显示类别 在顶部</span><br><span class="line"></span><br><span class="line">    &lt;org.tensorflow.demo.OverlayView</span><br><span class="line">        android:id=&quot;@+id/debug_overlay&quot;</span><br><span class="line">        android:layout_width=&quot;match_parent&quot;</span><br><span class="line">        android:layout_height=&quot;match_parent&quot;</span><br><span class="line">        android:layout_alignParentBottom=&quot;true&quot; /&gt;</span><br><span class="line"></span><br><span class="line">&lt;/RelativeLayout&gt;</span><br></pre></td></tr></table></figure>

<p>RecognitionScoreView 自定义控件用于显示识别结果<code>canvas.drawText(recog.getTitle() + &quot;: &quot; + recog.getConfidence(), x, y, fgPaint);</code></p>
<p>OverlayView 简单的提供回调的view，例如调试的时候，可用于显示调试中的图像等。</p>
<p>AutoFitTextureView 继承 TextureView</p>
<p>TextureView可用于显示流内容，可以是视频或者OpenGL场景。</p>
<p>surfaceview 窗口的工作方式是创建一个置于应用窗口之后的新窗口，效率高，因为刷新新窗口的时候，不需要重新绘制应用程序的窗口，但是surfaceview不在应用窗口上，所以不能使用view.setAlpha()之类的变换。也很难放在list view或者scrollview中。</p>
<p>Textureview在Android4.0引入，来解决上述问题，textureview必须在硬件加速器中开启。</p>
<p>AutoFitTextureView 在Textureview的基础上添加的长宽适应的功能。</p>
<p>Textureview主要用法设置 <code>TextureView.SurfaceTextureListener</code> </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">   * &#123;@link android.view.TextureView.SurfaceTextureListener&#125; handles several lifecycle events on a</span><br><span class="line">   * &#123;@link TextureView&#125;.</span><br><span class="line">   */</span><br><span class="line">  private final TextureView.SurfaceTextureListener surfaceTextureListener =</span><br><span class="line">      new TextureView.SurfaceTextureListener() &#123;</span><br><span class="line">        @Override</span><br><span class="line">        public void onSurfaceTextureAvailable(//初始化</span><br><span class="line">            final SurfaceTexture texture, final int width, final int height) &#123;</span><br><span class="line">          openCamera(width, height);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public void onSurfaceTextureSizeChanged(//size 变化时候</span><br><span class="line">            final SurfaceTexture texture, final int width, final int height) &#123;</span><br><span class="line">          configureTransform(width, height);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public boolean onSurfaceTextureDestroyed(final SurfaceTexture texture) &#123;</span><br><span class="line">          return true;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        @Override</span><br><span class="line">        public void onSurfaceTextureUpdated(final SurfaceTexture texture) &#123;&#125;</span><br><span class="line">      &#125;;</span><br></pre></td></tr></table></figure>

<p>打开摄像头，配置最合适的preview size</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">  * Opens the camera specified by &#123;@link CameraConnectionFragment#cameraId&#125;.</span><br><span class="line">  */</span><br><span class="line"> private void openCamera(final int width, final int height) &#123;</span><br><span class="line">   setUpCameraOutputs();//设置预览大小</span><br><span class="line">   configureTransform(width, height);//旋转偏移量</span><br><span class="line">   final Activity activity = getActivity();</span><br><span class="line">   final CameraManager manager = (CameraManager) activity.getSystemService(Context.CAMERA_SERVICE);</span><br><span class="line">   try &#123;</span><br><span class="line">     if (!cameraOpenCloseLock.tryAcquire(2500, TimeUnit.MILLISECONDS)) &#123;</span><br><span class="line">       throw new RuntimeException(&quot;Time out waiting to lock camera opening.&quot;);</span><br><span class="line">     &#125;</span><br><span class="line">     manager.openCamera(cameraId, stateCallback, backgroundHandler);//打开camera</span><br><span class="line">   &#125; catch (final CameraAccessException e) &#123;</span><br><span class="line">     LOGGER.e(e, &quot;Exception!&quot;);</span><br><span class="line">   &#125; catch (final InterruptedException e) &#123;</span><br><span class="line">     throw new RuntimeException(&quot;Interrupted while trying to lock camera opening.&quot;, e);</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p>stateCallback</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">  * &#123;@link android.hardware.camera2.CameraDevice.StateCallback&#125;</span><br><span class="line">  * is called when &#123;@link CameraDevice&#125; changes its state.</span><br><span class="line">  */</span><br><span class="line"> private final CameraDevice.StateCallback stateCallback =</span><br><span class="line">     new CameraDevice.StateCallback() &#123;</span><br><span class="line">       @Override</span><br><span class="line">       public void onOpened(final CameraDevice cd) &#123;</span><br><span class="line">         // This method is called when the camera is opened.  We start camera preview here.</span><br><span class="line">         cameraOpenCloseLock.release();</span><br><span class="line">         cameraDevice = cd;</span><br><span class="line">         createCameraPreviewSession();</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       @Override</span><br><span class="line">       public void onDisconnected(final CameraDevice cd) &#123;</span><br><span class="line">         cameraOpenCloseLock.release();</span><br><span class="line">         cd.close();</span><br><span class="line">         cameraDevice = null;</span><br><span class="line">       &#125;</span><br><span class="line"></span><br><span class="line">       @Override</span><br><span class="line">       public void onError(final CameraDevice cd, final int error) &#123;</span><br><span class="line">         cameraOpenCloseLock.release();</span><br><span class="line">         cd.close();</span><br><span class="line">         cameraDevice = null;</span><br><span class="line">         final Activity activity = getActivity();</span><br><span class="line">         if (null != activity) &#123;</span><br><span class="line">           activity.finish();</span><br><span class="line">         &#125;</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;;</span><br></pre></td></tr></table></figure>

<p>backgroundThread</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">  * Starts a background thread and its &#123;@link Handler&#125;.</span><br><span class="line">  */</span><br><span class="line"> private void startBackgroundThread() &#123;//在onresume的时候被调用</span><br><span class="line">   backgroundThread = new HandlerThread(&quot;ImageListener&quot;);</span><br><span class="line">   backgroundThread.start();</span><br><span class="line">   backgroundHandler = new Handler(backgroundThread.getLooper());</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p>其中 在camera onOpened() 的时候调用 createCameraPreviewSession</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">  * Creates a new &#123;@link CameraCaptureSession&#125; for camera preview.</span><br><span class="line">  */</span><br><span class="line"> private void createCameraPreviewSession() &#123;</span><br><span class="line">   try &#123;</span><br><span class="line">     final SurfaceTexture texture = textureView.getSurfaceTexture();</span><br><span class="line">     assert texture != null;</span><br><span class="line"></span><br><span class="line">     // We configure the size of default buffer to be the size of camera preview we want.</span><br><span class="line">     texture.setDefaultBufferSize(previewSize.getWidth(), previewSize.getHeight());</span><br><span class="line"></span><br><span class="line">     // This is the output Surface we need to start preview.</span><br><span class="line">     final Surface surface = new Surface(texture);</span><br><span class="line"></span><br><span class="line">     // We set up a CaptureRequest.Builder with the output Surface.</span><br><span class="line">     previewRequestBuilder = cameraDevice.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW);</span><br><span class="line">     previewRequestBuilder.addTarget(surface);</span><br><span class="line"></span><br><span class="line">     LOGGER.i(&quot;Opening camera preview: &quot; + previewSize.getWidth() + &quot;x&quot; + previewSize.getHeight());</span><br><span class="line"></span><br><span class="line">     // Create the reader for the preview frames.</span><br><span class="line">     previewReader =</span><br><span class="line">         ImageReader.newInstance(</span><br><span class="line">             previewSize.getWidth(), previewSize.getHeight(), ImageFormat.YUV_420_888, 2);</span><br><span class="line"></span><br><span class="line">     previewReader.setOnImageAvailableListener(imageListener, backgroundHandler);</span><br><span class="line">     previewRequestBuilder.addTarget(previewReader.getSurface());</span><br><span class="line"></span><br><span class="line">     // Here, we create a CameraCaptureSession for camera preview.</span><br><span class="line">     cameraDevice.createCaptureSession(</span><br><span class="line">         Arrays.asList(surface, previewReader.getSurface()),</span><br><span class="line">         new CameraCaptureSession.StateCallback() &#123;</span><br><span class="line"></span><br><span class="line">           @Override</span><br><span class="line">           public void onConfigured(final CameraCaptureSession cameraCaptureSession) &#123;</span><br><span class="line">             // The camera is already closed</span><br><span class="line">             if (null == cameraDevice) &#123;</span><br><span class="line">               return;</span><br><span class="line">             &#125;</span><br><span class="line"></span><br><span class="line">             // When the session is ready, we start displaying the preview.</span><br><span class="line">             captureSession = cameraCaptureSession;</span><br><span class="line">             try &#123;</span><br><span class="line">               // Auto focus should be continuous for camera preview.</span><br><span class="line">               previewRequestBuilder.set(</span><br><span class="line">                   CaptureRequest.CONTROL_AF_MODE,</span><br><span class="line">                   CaptureRequest.CONTROL_AF_MODE_CONTINUOUS_PICTURE);</span><br><span class="line">               // Flash is automatically enabled when necessary.</span><br><span class="line">               previewRequestBuilder.set(</span><br><span class="line">                   CaptureRequest.CONTROL_AE_MODE, CaptureRequest.CONTROL_AE_MODE_ON_AUTO_FLASH);</span><br><span class="line"></span><br><span class="line">               // Finally, we start displaying the camera preview.</span><br><span class="line">               previewRequest = previewRequestBuilder.build();</span><br><span class="line">               captureSession.setRepeatingRequest(</span><br><span class="line">                   previewRequest, captureCallback, backgroundHandler);</span><br><span class="line">             &#125; catch (final CameraAccessException e) &#123;</span><br><span class="line">               LOGGER.e(e, &quot;Exception!&quot;);</span><br><span class="line">             &#125;</span><br><span class="line">           &#125;</span><br><span class="line"></span><br><span class="line">           @Override</span><br><span class="line">           public void onConfigureFailed(final CameraCaptureSession cameraCaptureSession) &#123;</span><br><span class="line">             showToast(&quot;Failed&quot;);</span><br><span class="line">           &#125;</span><br><span class="line">         &#125;,</span><br><span class="line">         null);</span><br><span class="line">   &#125; catch (final CameraAccessException e) &#123;</span><br><span class="line">     LOGGER.e(e, &quot;Exception!&quot;);</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p>以上只是一些camera的操作和预览大小的设置</p>
<p>实际与识别相关的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line">   * Callback for android.hardware.Camera API</span><br><span class="line">   */</span><br><span class="line">  @Override</span><br><span class="line">  public void onPreviewFrame(final byte[] bytes, final Camera camera) &#123;</span><br><span class="line">    Log.i(&quot;linlian&quot;,&quot;CameraActivity.onPreviewFrame()&quot;);</span><br><span class="line">    if (isProcessingFrame) &#123;</span><br><span class="line">      LOGGER.w(&quot;Dropping frame!&quot;);//如果正在处理，则丢掉这一frame</span><br><span class="line">      return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    try &#123;</span><br><span class="line">      // Initialize the storage bitmaps once when the resolution is known.</span><br><span class="line">      if (rgbBytes == null) &#123;</span><br><span class="line">        Camera.Size previewSize = camera.getParameters().getPreviewSize();</span><br><span class="line">        previewHeight = previewSize.height;</span><br><span class="line">        previewWidth = previewSize.width;</span><br><span class="line">        rgbBytes = new int[previewWidth * previewHeight];//初始化 rgbBytes</span><br><span class="line">        onPreviewSizeChosen(new Size(previewSize.width, previewSize.height), 90);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; catch (final Exception e) &#123;</span><br><span class="line">      LOGGER.e(e, &quot;Exception!&quot;);</span><br><span class="line">      return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    isProcessingFrame = true;</span><br><span class="line">    lastPreviewFrame = bytes;</span><br><span class="line">    yuvBytes[0] = bytes;</span><br><span class="line">    yRowStride = previewWidth;</span><br><span class="line"></span><br><span class="line">    imageConverter =</span><br><span class="line">        new Runnable() &#123;</span><br><span class="line">          @Override</span><br><span class="line">          public void run() &#123;//最终调用native方法实现转化</span><br><span class="line">            ImageUtils.convertYUV420SPToARGB8888(bytes, previewWidth, previewHeight, rgbBytes);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">    postInferenceCallback =</span><br><span class="line">        new Runnable() &#123;</span><br><span class="line">          @Override</span><br><span class="line">          public void run() &#123;</span><br><span class="line">            camera.addCallbackBuffer(bytes);</span><br><span class="line">            isProcessingFrame = false;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">    processImage();//在子类实现图片处理</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>ClassifierActivity </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line"> protected void processImage() &#123;</span><br><span class="line">   rgbFrameBitmap.setPixels(getRgbBytes(), 0, previewWidth, 0, 0, previewWidth, previewHeight);</span><br><span class="line">   final Canvas canvas = new Canvas(croppedBitmap);</span><br><span class="line"></span><br><span class="line">   canvas.drawBitmap(rgbFrameBitmap, frameToCropTransform, null);</span><br><span class="line"></span><br><span class="line">   // For examining the actual TF input.</span><br><span class="line">   if (SAVE_PREVIEW_BITMAP) &#123;</span><br><span class="line">     ImageUtils.saveBitmap(croppedBitmap);</span><br><span class="line">   &#125;</span><br><span class="line">   </span><br><span class="line">   //将原始图片进行剪切处理成需要的尺寸croppedBitmap</span><br><span class="line">   </span><br><span class="line">   runInBackground(</span><br><span class="line">       new Runnable() &#123;</span><br><span class="line">         @Override</span><br><span class="line">         public void run() &#123;</span><br><span class="line">           final long startTime = SystemClock.uptimeMillis();</span><br><span class="line">           //进行识别</span><br><span class="line">           final List&lt;Classifier.Recognition&gt; results = classifier.recognizeImage(croppedBitmap);</span><br><span class="line"></span><br><span class="line">           lastProcessingTimeMs = SystemClock.uptimeMillis() - startTime;</span><br><span class="line">           LOGGER.i(&quot;Detect: %s&quot;, results);//[[838] pot (42.3%), [322] pineapple (12.4%)]</span><br><span class="line">           cropCopyBitmap = Bitmap.createBitmap(croppedBitmap);</span><br><span class="line">           if (resultsView == null) &#123;</span><br><span class="line">             resultsView = (ResultsView) findViewById(R.id.results);</span><br><span class="line">           &#125;</span><br><span class="line">           resultsView.setResults(results);</span><br><span class="line">           requestRender();</span><br><span class="line">           readyForNextImage();</span><br><span class="line">         &#125;</span><br><span class="line">       &#125;);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p><code>final List&lt;Classifier.Recognition&gt; results = classifier.recognizeImage(croppedBitmap);</code></p>
<p>详细i 看下TensorFlowImageClassifier</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">classifier =</span><br><span class="line">    TensorFlowImageClassifier.create(</span><br><span class="line">        getAssets(),</span><br><span class="line">        MODEL_FILE,</span><br><span class="line">        LABEL_FILE,</span><br><span class="line">        INPUT_SIZE,</span><br><span class="line">        IMAGE_MEAN,</span><br><span class="line">        IMAGE_STD,</span><br><span class="line">        INPUT_NAME,</span><br><span class="line">        OUTPUT_NAME);</span><br></pre></td></tr></table></figure>

<p>其中的几个参赛和所用的模型文件有关</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">private static final int INPUT_SIZE = 224;</span><br><span class="line">private static final int IMAGE_MEAN = 117;</span><br><span class="line">private static final float IMAGE_STD = 1;</span><br><span class="line">private static final String INPUT_NAME = &quot;input&quot;;</span><br><span class="line">private static final String OUTPUT_NAME = &quot;output&quot;;</span><br></pre></td></tr></table></figure>

<p>主要是在 TensorFlowImageClassifier</p>
<p>我们有两个文件，一个是模型文件pb结尾的，一个是标签文件，txt结尾的，TensorFlowImageClassifier需要读取模型和标签文件，然后在使用模型去识别处理新的文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">private static final String MODEL_FILE = &quot;file:///android_asset/tensorflow_inception_graph.pb&quot;;</span><br><span class="line">private static final String LABEL_FILE =</span><br><span class="line">    &quot;file:///android_asset/imagenet_comp_graph_label_strings.txt&quot;;</span><br></pre></td></tr></table></figure>

<p>读取标签文件并且添加到列表中标签列表 <code>private Vector&lt;String&gt; labels = new Vector&lt;String&gt;();</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">String actualFilename = labelFilename.split(&quot;file:///android_asset/&quot;)[1];</span><br><span class="line">    Log.i(TAG, &quot;Reading labels from: &quot; + actualFilename);</span><br><span class="line">    BufferedReader br = null;</span><br><span class="line">    try &#123;</span><br><span class="line">      br = new BufferedReader(new InputStreamReader(assetManager.open(actualFilename)));</span><br><span class="line">      String line;</span><br><span class="line">      while ((line = br.readLine()) != null) &#123;</span><br><span class="line">        c.labels.add(line);</span><br><span class="line">      &#125;</span><br><span class="line">      br.close();</span><br><span class="line">    &#125; catch (IOException e) &#123;</span><br><span class="line">      throw new RuntimeException(&quot;Problem reading label file!&quot; , e);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>加载模型，查看 TensorFlowInferenceInterface内部代码，大概就是加载文件后，该文件是一个byte[] graphDef ，图标定义的学习模型，通过this.loadGraph(graphDef, this.g);得到Graph对象</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c.inferenceInterface = new TensorFlowInferenceInterface(assetManager, modelFilename);</span><br></pre></td></tr></table></figure>

<p>完成以上两步后，只要对图片进行合理的处理后，作为输入，就可以得到tensor flow模型给出的识别结果了</p>
<p>输入输出的一些数据定义则需要深刻理解模型的定义。The shape of the output is [N, NUM_CLASSES], where N is the batch size.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">c.outputNames = new String[] &#123;outputName&#125;;//输出</span><br><span class="line">c.intValues = new int[inputSize * inputSize];//输入是一组大小为inputSize * inputSize的int数据，需要将图片信息转化为这种数据</span><br><span class="line">c.floatValues = new float[inputSize * inputSize * 3];</span><br><span class="line">c.outputs = new float[numClasses];</span><br></pre></td></tr></table></figure>

<p>识别处理</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line"> public List&lt;Recognition&gt; recognizeImage(final Bitmap bitmap) &#123;</span><br><span class="line">     Log.i(&quot;linlian&quot;,&quot;recognizeImage&quot;);</span><br><span class="line">   // Log this method so that it can be analyzed with systrace.</span><br><span class="line">   Trace.beginSection(&quot;recognizeImage&quot;);</span><br><span class="line"></span><br><span class="line">   Trace.beginSection(&quot;preprocessBitmap&quot;);</span><br><span class="line">   // Preprocess the image data from 0-255 int to normalized float based</span><br><span class="line">   // on the provided parameters.</span><br><span class="line">   bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());</span><br><span class="line">     Log.i(&quot;linlian&quot;,&quot;recognizeImage intValues.length=&quot;+intValues.length);</span><br><span class="line">   for (int i = 0; i &lt; intValues.length; ++i) &#123;</span><br><span class="line">     final int val = intValues[i];</span><br><span class="line">     floatValues[i * 3 + 0] = (((val &gt;&gt; 16) &amp; 0xFF) - imageMean) / imageStd;</span><br><span class="line">     floatValues[i * 3 + 1] = (((val &gt;&gt; 8) &amp; 0xFF) - imageMean) / imageStd;</span><br><span class="line">     floatValues[i * 3 + 2] = ((val &amp; 0xFF) - imageMean) / imageStd;</span><br><span class="line">     //Log.i(&quot;linlian&quot;,&quot; i=&quot;+i+&quot;  &quot;+floatValues[i * 3 + 0]+&quot; &quot;+floatValues[i * 3 + 0]+&quot;  &quot;+floatValues[i * 3 + 0]);</span><br><span class="line">   &#125;</span><br><span class="line">   Trace.endSection();</span><br><span class="line"></span><br><span class="line">   // Copy the input data into TensorFlow.	输入</span><br><span class="line">   Trace.beginSection(&quot;feed&quot;);</span><br><span class="line">   inferenceInterface.feed(inputName, floatValues, 1, inputSize, inputSize, 3);</span><br><span class="line">   Trace.endSection();</span><br><span class="line"></span><br><span class="line">   // Run the inference call.运行</span><br><span class="line">   Trace.beginSection(&quot;run&quot;);</span><br><span class="line">   inferenceInterface.run(outputNames, logStats);</span><br><span class="line">   Trace.endSection();</span><br><span class="line"></span><br><span class="line">   // Copy the output Tensor back into the output array.</span><br><span class="line">   Trace.beginSection(&quot;fetch&quot;);输出</span><br><span class="line">   inferenceInterface.fetch(outputName, outputs);</span><br><span class="line">   Trace.endSection();</span><br><span class="line"></span><br><span class="line">   // Find the best classifications.</span><br><span class="line">   PriorityQueue&lt;Recognition&gt; pq =</span><br><span class="line">       new PriorityQueue&lt;Recognition&gt;(</span><br><span class="line">           3,</span><br><span class="line">           new Comparator&lt;Recognition&gt;() &#123;</span><br><span class="line">             @Override</span><br><span class="line">             public int compare(Recognition lhs, Recognition rhs) &#123;</span><br><span class="line">               // Intentionally reversed to put high confidence at the head of the queue.</span><br><span class="line">               return Float.compare(rhs.getConfidence(), lhs.getConfidence());</span><br><span class="line">             &#125;</span><br><span class="line">           &#125;);</span><br><span class="line">   for (int i = 0; i &lt; outputs.length; ++i) &#123;</span><br><span class="line">     if (outputs[i] &gt; THRESHOLD) &#123;</span><br><span class="line">       pq.add(</span><br><span class="line">           new Recognition(</span><br><span class="line">               &quot;&quot; + i, labels.size() &gt; i ? labels.get(i) : &quot;unknown&quot;, outputs[i], null));</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   final ArrayList&lt;Recognition&gt; recognitions = new ArrayList&lt;Recognition&gt;();</span><br><span class="line">   int recognitionsSize = Math.min(pq.size(), MAX_RESULTS);</span><br><span class="line">   for (int i = 0; i &lt; recognitionsSize; ++i) &#123;</span><br><span class="line">     recognitions.add(pq.poll());</span><br><span class="line">   &#125;</span><br><span class="line">   Trace.endSection(); // &quot;recognizeImage&quot;</span><br><span class="line">   return recognitions;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<h3 id="检测-detector"><a href="#检测-detector" class="headerlink" title="检测 detector"></a>检测 detector</h3><p>关于检测</p>
<p>加载的模型是由三种 可选 multi box，使用旧的API训练的模型 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">private static final String MB_INPUT_NAME = &quot;ResizeBilinear&quot;;</span><br><span class="line">private static final String MB_OUTPUT_LOCATIONS_NAME = &quot;output_locations/Reshape&quot;;</span><br><span class="line">private static final String MB_OUTPUT_SCORES_NAME = &quot;output_scores/Reshape&quot;;</span><br><span class="line">private static final String MB_MODEL_FILE = &quot;file:///android_asset/multibox_model.pb&quot;;</span><br><span class="line">private static final String MB_LOCATION_FILE =</span><br><span class="line">    &quot;file:///android_asset/multibox_location_priors.txt&quot;;</span><br></pre></td></tr></table></figure>

<p>另外一部分 tensor flow object detect</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">private static final int TF_OD_API_INPUT_SIZE = 300;</span><br><span class="line"> private static final String TF_OD_API_MODEL_FILE =</span><br><span class="line">     &quot;file:///android_asset/ssd_mobilenet_v1_android_export.pb&quot;;</span><br><span class="line"> private static final String TF_OD_API_LABELS_FILE = &quot;file:///android_asset/coco_labels_list.txt&quot;;</span><br></pre></td></tr></table></figure>

<p>还有yolo??</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">// Configuration values for tiny-yolo-voc. Note that the graph is not included with TensorFlow and</span><br><span class="line">// must be manually placed in the assets/ directory by the user.</span><br><span class="line">// Graphs and models downloaded from http://pjreddie.com/darknet/yolo/ may be converted e.g. via</span><br><span class="line">// DarkFlow (https://github.com/thtrieu/darkflow). Sample command:</span><br><span class="line">// ./flow --model cfg/tiny-yolo-voc.cfg --load bin/tiny-yolo-voc.weights --savepb --verbalise</span><br><span class="line">private static final String YOLO_MODEL_FILE = &quot;file:///android_asset/graph-tiny-yolo-voc.pb&quot;;</span><br><span class="line">private static final int YOLO_INPUT_SIZE = 416;</span><br><span class="line">private static final String YOLO_INPUT_NAME = &quot;input&quot;;</span><br><span class="line">private static final String YOLO_OUTPUT_NAMES = &quot;output&quot;;</span><br><span class="line">private static final int YOLO_BLOCK_SIZE = 32;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>yolo 是一个实时物体识别的</p>
<p>You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Pascal Titan X it processes images at 30 FPS and has a mAP of 57.9% on COCO test-dev.</p>
</blockquote>
<p>主要看下tensorflow TF_OD 相关的</p>
<p>coco_labels_list.txt 标签文件，人啊，自行车啊，识别</p>
<p>ssd_mobilenet_v1_android_export.pb 模型文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tracker = new MultiBoxTracker(this);</span><br><span class="line">detector = TensorFlowObjectDetectionAPIModel.create(</span><br><span class="line">            getAssets(), TF_OD_API_MODEL_FILE, TF_OD_API_LABELS_FILE, TF_OD_API_INPUT_SIZE);</span><br><span class="line">        cropSize = TF_OD_API_INPUT_SIZE;</span><br></pre></td></tr></table></figure>

<p>模型的读取和输入输出定义 TensorFlowObjectDetectionAPIModel</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">public static Classifier create(</span><br><span class="line">      final AssetManager assetManager,</span><br><span class="line">      final String modelFilename,</span><br><span class="line">      final String labelFilename,</span><br><span class="line">      final int inputSize) throws IOException &#123;</span><br><span class="line">    final TensorFlowObjectDetectionAPIModel d = new TensorFlowObjectDetectionAPIModel();</span><br><span class="line"></span><br><span class="line">    InputStream labelsInput = null;</span><br><span class="line">    String actualFilename = labelFilename.split(&quot;file:///android_asset/&quot;)[1];</span><br><span class="line">    labelsInput = assetManager.open(actualFilename);</span><br><span class="line">    BufferedReader br = null;</span><br><span class="line">    br = new BufferedReader(new InputStreamReader(labelsInput));</span><br><span class="line">    String line;</span><br><span class="line">    while ((line = br.readLine()) != null) &#123;</span><br><span class="line">      LOGGER.w(line);</span><br><span class="line">      d.labels.add(line);//逐行读取标签文件</span><br><span class="line">    &#125;</span><br><span class="line">    br.close();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    d.inferenceInterface = new TensorFlowInferenceInterface(assetManager, modelFilename);</span><br><span class="line"></span><br><span class="line">    final Graph g = d.inferenceInterface.graph();</span><br><span class="line"></span><br><span class="line">    d.inputName = &quot;image_tensor&quot;;//输入的shap定义</span><br><span class="line">    // The inputName node has a shape of [N, H, W, C], where</span><br><span class="line">    // N is the batch size</span><br><span class="line">    // H = W are the height and width</span><br><span class="line">    // C is the number of channels (3 for our purposes - RGB)</span><br><span class="line">    final Operation inputOp = g.operation(d.inputName);</span><br><span class="line">    if (inputOp == null) &#123;</span><br><span class="line">      throw new RuntimeException(&quot;Failed to find input Node &apos;&quot; + d.inputName + &quot;&apos;&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    d.inputSize = inputSize;</span><br><span class="line">    // The outputScoresName node has a shape of [N, NumLocations], where N</span><br><span class="line">    // is the batch size.  三个输出</span><br><span class="line">    final Operation outputOp1 = g.operation(&quot;detection_scores&quot;);</span><br><span class="line">    if (outputOp1 == null) &#123;</span><br><span class="line">      throw new RuntimeException(&quot;Failed to find output Node &apos;detection_scores&apos;&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    final Operation outputOp2 = g.operation(&quot;detection_boxes&quot;);</span><br><span class="line">    if (outputOp2 == null) &#123;</span><br><span class="line">      throw new RuntimeException(&quot;Failed to find output Node &apos;detection_boxes&apos;&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">    final Operation outputOp3 = g.operation(&quot;detection_classes&quot;);</span><br><span class="line">    if (outputOp3 == null) &#123;</span><br><span class="line">      throw new RuntimeException(&quot;Failed to find output Node &apos;detection_classes&apos;&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // Pre-allocate buffers.</span><br><span class="line">    d.outputNames = new String[] &#123;&quot;detection_boxes&quot;, &quot;detection_scores&quot;,</span><br><span class="line">                                  &quot;detection_classes&quot;, &quot;num_detections&quot;&#125;;</span><br><span class="line">    d.intValues = new int[d.inputSize * d.inputSize];</span><br><span class="line">    d.byteValues = new byte[d.inputSize * d.inputSize * 3];</span><br><span class="line">    d.outputScores = new float[MAX_RESULTS];</span><br><span class="line">    d.outputLocations = new float[MAX_RESULTS * 4];</span><br><span class="line">    d.outputClasses = new float[MAX_RESULTS];</span><br><span class="line">    d.outputNumDetections = new float[1];</span><br><span class="line">    return d;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>识别</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">@Override</span><br><span class="line">  public List&lt;Recognition&gt; recognizeImage(final Bitmap bitmap) &#123;</span><br><span class="line">    // Log this method so that it can be analyzed with systrace.</span><br><span class="line">    Trace.beginSection(&quot;recognizeImage&quot;);</span><br><span class="line"></span><br><span class="line">    Trace.beginSection(&quot;preprocessBitmap&quot;);</span><br><span class="line">    // Preprocess the image data from 0-255 int to normalized float based</span><br><span class="line">    // on the provided parameters.</span><br><span class="line">    bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());</span><br><span class="line"></span><br><span class="line">    for (int i = 0; i &lt; intValues.length; ++i) &#123;//图片数据处理</span><br><span class="line">      byteValues[i * 3 + 2] = (byte) (intValues[i] &amp; 0xFF);</span><br><span class="line">      byteValues[i * 3 + 1] = (byte) ((intValues[i] &gt;&gt; 8) &amp; 0xFF);</span><br><span class="line">      byteValues[i * 3 + 0] = (byte) ((intValues[i] &gt;&gt; 16) &amp; 0xFF);</span><br><span class="line">    &#125;</span><br><span class="line">    Trace.endSection(); // preprocessBitmap</span><br><span class="line"></span><br><span class="line">    // Copy the input data into TensorFlow.输入</span><br><span class="line">    Trace.beginSection(&quot;feed&quot;);</span><br><span class="line">    inferenceInterface.feed(inputName, byteValues, 1, inputSize, inputSize, 3);</span><br><span class="line">    Trace.endSection();</span><br><span class="line"></span><br><span class="line">    // Run the inference call.运行</span><br><span class="line">    Trace.beginSection(&quot;run&quot;);</span><br><span class="line">    inferenceInterface.run(outputNames, logStats);</span><br><span class="line">    Trace.endSection();</span><br><span class="line"></span><br><span class="line">    // Copy the output Tensor back into the output array.结果输出</span><br><span class="line">    Trace.beginSection(&quot;fetch&quot;);</span><br><span class="line">    outputLocations = new float[MAX_RESULTS * 4];</span><br><span class="line">    outputScores = new float[MAX_RESULTS];</span><br><span class="line">    outputClasses = new float[MAX_RESULTS];</span><br><span class="line">    outputNumDetections = new float[1];</span><br><span class="line">    inferenceInterface.fetch(outputNames[0], outputLocations);</span><br><span class="line">    inferenceInterface.fetch(outputNames[1], outputScores);</span><br><span class="line">    inferenceInterface.fetch(outputNames[2], outputClasses);</span><br><span class="line">    inferenceInterface.fetch(outputNames[3], outputNumDetections);</span><br><span class="line">    Trace.endSection();</span><br><span class="line"></span><br><span class="line">    // Find the best detections.</span><br><span class="line">    final PriorityQueue&lt;Recognition&gt; pq =</span><br><span class="line">        new PriorityQueue&lt;Recognition&gt;(</span><br><span class="line">            1,</span><br><span class="line">            new Comparator&lt;Recognition&gt;() &#123;</span><br><span class="line">              @Override</span><br><span class="line">              public int compare(final Recognition lhs, final Recognition rhs) &#123;</span><br><span class="line">                // Intentionally reversed to put high confidence at the head of the queue.</span><br><span class="line">                return Float.compare(rhs.getConfidence(), lhs.getConfidence());</span><br><span class="line">              &#125;</span><br><span class="line">            &#125;);</span><br><span class="line"></span><br><span class="line">    // Scale them back to the input size.</span><br><span class="line">    for (int i = 0; i &lt; outputScores.length; ++i) &#123;</span><br><span class="line">      final RectF detection =</span><br><span class="line">          new RectF(</span><br><span class="line">              outputLocations[4 * i + 1] * inputSize,</span><br><span class="line">              outputLocations[4 * i] * inputSize,</span><br><span class="line">              outputLocations[4 * i + 3] * inputSize,</span><br><span class="line">              outputLocations[4 * i + 2] * inputSize);</span><br><span class="line">      pq.add(</span><br><span class="line">          new Recognition(&quot;&quot; + i, labels.get((int) outputClasses[i]), outputScores[i], detection));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    final ArrayList&lt;Recognition&gt; recognitions = new ArrayList&lt;Recognition&gt;();</span><br><span class="line">    for (int i = 0; i &lt; Math.min(pq.size(), MAX_RESULTS); ++i) &#123;</span><br><span class="line">      recognitions.add(pq.poll());</span><br><span class="line">    &#125;</span><br><span class="line">    Trace.endSection(); // &quot;recognizeImage&quot;</span><br><span class="line">    return recognitions;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h1 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h1><p>运行手写识别</p>
<p>只需要直接运行<code>fully_connected_feed.py</code>文件，就可以开始训练：</p>
<p><code>python fully_connected_feed.py</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line"></span><br><span class="line">  File &quot;fully_connected_feed.py&quot;, line 279, in &lt;module&gt;</span><br><span class="line"></span><br><span class="line">    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)</span><br><span class="line"></span><br><span class="line">TypeError: run() got an unexpected keyword argument &apos;main&apos;</span><br></pre></td></tr></table></figure>

<p>版本太低？</p>
<p>Pip3 install tensorflow==1.4.0   </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(venv) zowee-laiscdeMacBook-Pro:tensorflow zowee-laisc$ pip3 install --upgrade tensorflow==1.6.0</span><br></pre></td></tr></table></figure>

<p><strong>TensorFlow Python API 依赖 Python 2.7 版本.</strong></p>
<p>yong pycharm 新建2.7环境的python项目</p>
<p>激活 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"> source venv/bin/activate</span><br></pre></td></tr></table></figure>

<p>安装tensor flow</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade tensorflow==1.6.0</span><br></pre></td></tr></table></figure>

<p>到下载的tensorflow</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorflow/tensorflow/tensorflow/examples/tutorials/mnist</span><br></pre></td></tr></table></figure>

<p>运行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">(venv) zowee-laiscdeMacBook-Pro:mnist zowee-laisc$ python fully_connected_feed.py </span><br><span class="line">Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.</span><br><span class="line">Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz</span><br><span class="line">Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.</span><br><span class="line">Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz</span><br><span class="line">Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.</span><br><span class="line">Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.</span><br><span class="line">Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz</span><br><span class="line">2018-05-22 16:15:26.976082: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA</span><br><span class="line">Step 0: loss = 2.32 (0.215 sec)</span><br><span class="line">Step 100: loss = 2.13 (0.001 sec)</span><br><span class="line">Step 200: loss = 1.96 (0.001 sec)</span><br><span class="line">Step 300: loss = 1.70 (0.001 sec)</span><br><span class="line">Step 400: loss = 1.31 (0.001 sec)</span><br><span class="line">Step 500: loss = 1.11 (0.001 sec)</span><br><span class="line">Step 600: loss = 0.89 (0.001 sec)</span><br><span class="line">Step 700: loss = 0.87 (0.001 sec)</span><br><span class="line">Step 800: loss = 0.70 (0.001 sec)</span><br><span class="line">Step 900: loss = 0.64 (0.001 sec)</span><br><span class="line">Training Data Eval:</span><br><span class="line">Num examples: 55000  Num correct: 46676  Precision @ 1: 0.8487</span><br><span class="line">Validation Data Eval:</span><br><span class="line">Num examples: 5000  Num correct: 4264  Precision @ 1: 0.8528</span><br><span class="line">Test Data Eval:</span><br><span class="line">Num examples: 10000  Num correct: 8526  Precision @ 1: 0.8526</span><br><span class="line">Step 1000: loss = 0.55 (0.012 sec)</span><br><span class="line">Step 1100: loss = 0.58 (0.123 sec)</span><br><span class="line">Step 1200: loss = 0.40 (0.001 sec)</span><br><span class="line">Step 1300: loss = 0.49 (0.001 sec)</span><br><span class="line">Step 1400: loss = 0.37 (0.001 sec)</span><br><span class="line">Step 1500: loss = 0.70 (0.001 sec)</span><br><span class="line">Step 1600: loss = 0.40 (0.001 sec)</span><br><span class="line">Step 1700: loss = 0.24 (0.001 sec)</span><br><span class="line">Step 1800: loss = 0.31 (0.001 sec)</span><br><span class="line">Step 1900: loss = 0.39 (0.001 sec)</span><br><span class="line">Training Data Eval:</span><br><span class="line">Num examples: 55000  Num correct: 49053  Precision @ 1: 0.8919</span><br><span class="line">Validation Data Eval:</span><br><span class="line">Num examples: 5000  Num correct: 4509  Precision @ 1: 0.9018</span><br><span class="line">Test Data Eval:</span><br><span class="line">Num examples: 10000  Num correct: 8971  Precision @ 1: 0.8971</span><br><span class="line">(venv) zowee-laiscdeMacBook-Pro:mnist zowee-laisc$</span><br></pre></td></tr></table></figure>

<p>启动tensorboard</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(venv) zowee-laiscdeMacBook-Pro:mnist zowee-laisc$ tensorboard --logdir=logs/</span><br><span class="line">TensorBoard 1.6.0 at http://zowee-laiscdeMacBook-Pro.local:6006 (Press CTRL+C to quit)</span><br></pre></td></tr></table></figure>


      </div>
      <div class="post-copyright">
    <p class="copyright-item">
      <span>原文作者: </span>
      <a href="https://lynn8570.github.io">lynn8570</a>
    </p>
    <p class="copyright-item">
      <span>原文链接: </span>
      <a href="https://lynn8570.github.io/2018/05/31/tensorflow/">https://lynn8570.github.io/2018/05/31/tensorflow/</a>
    </p>
    <p class="copyright-item">
      <span>许可协议: </span><a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>
    </p>
  </div>
      <footer class="post-footer">
        
        <nav class="post-nav"><a class="prev" href="/2019/06/29/hello-world/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Hello World</span>
        <span class="prev-text nav-mobile">上一篇</span>
      </a>
    <a class="next" href="/2018/05/11/android_studio_opencv/">
        <span class="next-text nav-default">使用Android studio导入open cv 示例代码</span>
        <span class="prev-text nav-mobile">下一篇</span>
        <i class="iconfont icon-right"></i>
      </a>
    </nav></footer>
    </article></div><div class="comments" id="comments"></div></div>
      </main>

      <footer id="footer" class="footer"><div class="social-links"><a href="mailto:your@email.com" class="iconfont icon-email" title="email"></a>
        <a href="https://github.com/ahonn" class="iconfont icon-github" title="github"></a>
        <a href="/atom.xml" class="iconfont icon-rss" title="rss"></a>
    </div><div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://hexo.io/">Hexo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/ahonn/hexo-theme-even">Even</a>
  </span>

  <span class="copyright-year">&copy;2015 - 2019<span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">lynn8570</span>
  </span>
</div>
</footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div><script type="text/javascript" src="/lib/jquery/jquery.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/lib/pjax/jquery.pjax.min.js"></script>
  <script type="text/javascript" src="/lib/nprogress/nprogress.min.js"></script>
  <script type="text/javascript" src="/js/src/even.js?v=2.11.0"></script>
</body>
</html>
